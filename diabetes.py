# -*- coding: utf-8 -*-
"""diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rre7SBtQxMiPPAiB8jnemnzo3YCSGf_s

# Proyek Klasifikasi Gambar: [Diabetes National Institute of Diabetes and Digestive and Kidney]
- **Nama:** I Dewa Gede Mahesta Parawangsa
- **Email:** dewamahesta2711@gmail.com
- **ID Dicoding:** demahesta

## Import Semua Packages/Library yang Digunakan
"""

pip install Lazypredict

import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from google.colab import files
from sklearn.feature_selection import SelectKBest, f_classif
from lazypredict.Supervised import LazyClassifier
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from imblearn.over_sampling import SMOTE
from sklearn.tree import DecisionTreeClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

"""## Data Preparation

### Data Loading
"""

# Define the filename
file_name = 'diabetes.csv'
try:
    df = pd.read_csv(file_name)

    # Display the first 5 rows of the DataFrame to verify it loaded correctly
    print(f"Successfully loaded '{file_name}'. Displaying the first 5 rows:")
    print(df.head())

except FileNotFoundError:
    # Handle the case where the file wasn't found
    print(f"Error: File not found.")
    print(f"Please make sure '{file_name}' is uploaded to the Colab session storage.")
    print("Follow the upload instructions in the code comments.")

df.info()

df.head()

df.describe()

"""### Data Preprocessing

#### Cleaning
"""

print("\nJumlah Nilai 0 dalam Setiap Kolom:")
zero_counts = (df == 0).sum()
print(zero_counts)

invalid_zero_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
df[invalid_zero_columns] = df[invalid_zero_columns].replace(0, np.nan)

imputer = IterativeImputer(
    max_iter=10,
    random_state=42
)

# Only impute on columns that previously contained NaN
df[invalid_zero_columns] = imputer.fit_transform(df[invalid_zero_columns])

# Recheck the number of 0 (or NaN) values after imputation
print("\nJumlah Nilai Kosong Setelah Imputasi:")
print(df[invalid_zero_columns].isna().sum())

# Checking for duplicates
duplicates = df.duplicated().sum()
print(f"\nJumlah Baris Duplikat: {duplicates}")

# Remove duplicate rows
df.drop_duplicates(inplace=True)

# Rechecking the number of duplicate rows
duplicates_after = df.duplicated().sum()
print(f"Jumlah Baris Duplikat Setelah Penghapusan: {duplicates_after}")

# Display the first few rows of the dataset after cleaning
print("\nData Setelah Cleaning:")
print(df.head())

# Save the cleaned dataset to a new file
df.to_csv('diabetes.csv', index=False)

"""## Exploratory Data Analysis

### Categorical Data Analysis
"""

# Check the distribution of the Outcome column
print("\nDistribution of Outcome:")
print(df['Outcome'].value_counts())

# Plot countplot for the Outcome column
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='Outcome')
plt.title('Countplot of Outcome')
plt.xlabel('Outcome')
plt.ylabel('Count')
plt.show()

# List all columns in the dataset
print("\nColumns in the dataset:")
print(df.columns)

"""### Numerical Data Analysis"""

# Define columns to plot
columns_to_plot = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age', 'DiabetesPedigreeFunction']

# Create subplots for boxplots and histograms
num_cols = len(columns_to_plot)
fig, axes = plt.subplots(nrows=num_cols, ncols=2, figsize=(15, 4 * num_cols))

for i, column in enumerate(columns_to_plot):
    # Boxplot
    sns.boxplot(data=df, x=column, ax=axes[i, 0])
    axes[i, 0].set_title(f'Boxplot of {column}')
    axes[i, 0].set_xlabel(column)

    # Histogram
    sns.histplot(data=df[column], ax=axes[i, 1])
    axes[i, 1].set_title(f'Histogram of {column}')
    axes[i, 1].set_xlabel(column)
    axes[i, 1].set_ylabel('Count')

plt.tight_layout()
plt.show()

# Function to identify outliers based on specified thresholds
def identify_outliers(df, column, lower_bound=None, upper_bound=None):
    mask = pd.Series(False, index=df.index)
    if lower_bound is not None:
        mask |= df[column] < lower_bound
    if upper_bound is not None:
        mask |= df[column] > upper_bound
    return df[mask]

# Function to remove outliers based on specified method and threshold
def remove_outliers(df, column, lower_bound=None, upper_bound=None):
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Define columns to check for outliers
columns_to_check = ['BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age']

# Define custom bounds for each column
custom_bounds = {
    'BloodPressure': {'lower': 0, 'upper': 200},
    'SkinThickness': {'lower': 0, 'upper': 100},
    'Insulin': {'lower': 0, 'upper': 850},
    'BMI': {'lower': 0, 'upper': 70},
    'Age': {'lower': 0, 'upper': 100},
}

# Display information about outliers for each specified column
for column in columns_to_check:
    lower_bound = custom_bounds[column]['lower']
    upper_bound = custom_bounds[column]['upper']

    outliers = identify_outliers(df, column, lower_bound=lower_bound, upper_bound=upper_bound)

    print(f"\nOutliers in {column}:")
    print(outliers)
    print(f"Total outliers in {column}: {outliers.shape[0]}")

# Remove outliers for each specified column using custom bounds
df_clean = df.copy()
for column in columns_to_check:
    lower_bound = custom_bounds[column]['lower']
    upper_bound = custom_bounds[column]['upper']

    df_clean = remove_outliers(df_clean, column, lower_bound=lower_bound, upper_bound=upper_bound)

# Display the first few rows of the dataset after removing outliers
print("\nFirst few rows of the dataset after removing outliers:")
print(df_clean.head())

# Check the distribution of each column using boxplots and histograms
fig, axes = plt.subplots(nrows=len(columns_to_check), ncols=2, figsize=(15, 4 * len(columns_to_check)))

for i, column in enumerate(columns_to_check):
    # Boxplot
    sns.boxplot(data=df_clean, x=column, ax=axes[i, 0])
    axes[i, 0].set_title(f'Boxplot of {column} (After Removing Outliers)')
    axes[i, 0].set_xlabel(column)

    # Histogram
    sns.histplot(data=df_clean[column], ax=axes[i, 1])
    axes[i, 1].set_title(f'Histogram of {column} (After Removing Outliers)')
    axes[i, 1].set_xlabel(column)
    axes[i, 1].set_ylabel('Count')

plt.tight_layout()
plt.show()

# Select only numerical columns
numerical_cols = df.select_dtypes(include=['number']).columns
print("Numerical Columns:", numerical_cols)

# Exclude the 'Outcome' and 'id' columns if they exist
numerical_cols = numerical_cols.drop('Outcome', errors='ignore')
numerical_cols = numerical_cols.drop('Id', errors='ignore')

# Create a pairplot for the numerical columns
sns.pairplot(
    df[numerical_cols],
    diag_kind='kde',
    plot_kws={'alpha': 0.5},
    height=2.5
)

# Adjust layout to prevent overlap
plt.tight_layout()

# Show the plot
plt.show()

# Select only numerical columns and drop the 'Id' column if it exists
numerical_cols = df_clean.select_dtypes(include=['number']).columns
numerical_cols = numerical_cols.drop('Id', errors='ignore')

# Filter the DataFrame to include only the selected numerical columns
df_clean = df_clean[numerical_cols]

# Calculate the correlation matrix
corr_matrix = df_clean.corr()

# Display the correlation matrix
print("Correlation Matrix:")

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(
    corr_matrix,
    annot=True,
    cmap='coolwarm',
    fmt=".2f",
    linewidths=0.5
)
plt.title('Heatmap of Feature Correlations')
plt.show()

# Separate features and target variable, dropping 'Id' if it exists
X = df_clean.drop(['Outcome', 'Id'], axis=1, errors='ignore')
y = df_clean['Outcome']

"""## Split Dataset"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the shapes of the resulting datasets
print("\nShapes of the datasets:")
print(f"X_train: {X_train.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_test: {y_test.shape}")

#SMOTE for balance 2 class
sm = SMOTE(random_state=42)
X_train, y_train = sm.fit_resample(X_train, y_train)

"""## Modelling"""

#Lazy Classifier Method for ML Comparison
clf = LazyClassifier(
    verbose=0,
    ignore_warnings=True,
    custom_metric=None
)
models, predictions = clf.fit(X_train, X_test, y_train, y_test)
print(models)

# Define the models and respective hyperparameter grids
models = {
    'DecisionTree': {
        'model': DecisionTreeClassifier(),
        'params': {
            'criterion': ['gini', 'entropy'],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
    },
    'LGBM': {
        'model': LGBMClassifier(verbosity=-1),
        'params': {
            'n_estimators': [100, 200, 300],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.2],
            'num_leaves': [20, 31, 40]
        }
    },
    'XGBoost': {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0),
        'params': {
            'n_estimators': [100, 200, 300],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.2],
            'subsample': [0.6, 0.8, 1.0]
        }
    }
}

"""## Evaluasi dan Visualisasi"""

# Lists to store evaluation metrics
accuracies = []
train_accuracies = []
best_params_list = []
classification_reports = []
confusion_matrices = []

# Train and evaluate each model
for model_name, model_info in models.items():
    print(f"\n--- {model_name} ---")

    # Initialize GridSearchCV with return_train_score
    clf = GridSearchCV(
        estimator=model_info['model'],
        param_grid=model_info['params'],
        scoring='accuracy',
        cv=5,
        return_train_score=True,
        verbose=0
    )

    # Fit GridSearchCV
    clf.fit(X_train, y_train)

    # Simpan hasil CV ke DataFrame
    results = pd.DataFrame(clf.cv_results_)
    print("\nCV results (train vs test):")
    print(results[['mean_train_score', 'mean_test_score', 'std_test_score']])

    # Get best model and parameters
    best_model = clf.best_estimator_
    best_params = clf.best_params_

    # Evaluate on training set
    y_train_pred = best_model.predict(X_train)
    train_accuracy = accuracy_score(y_train, y_train_pred)

    # Evaluate on test set
    y_pred = best_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    # Save metrics
    accuracies.append((model_name, accuracy))
    train_accuracies.append((model_name, train_accuracy))
    best_params_list.append((model_name, best_params))
    classification_reports.append((model_name, classification_report(y_test, y_pred, output_dict=True)))
    confusion_matrices.append((model_name, confusion_matrix(y_test, y_pred)))

    # Show summary
    print(f"\nBest Parameters: {best_params}")
    print(f"Test Accuracy: {accuracy:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

# Convert accuracies to DataFrame
accuracies_df = pd.DataFrame(accuracies, columns=['Model', 'Test Accuracy'])
train_accuracies_df = pd.DataFrame(train_accuracies, columns=['Model', 'Train Accuracy'])

# Function to add annotations to bar plot
def annotate_bars(ax):
    for p in ax.patches:
        height = p.get_height()
        # Adjust the position of the annotation
        ax.annotate(f'{height:.4f}',
                    (p.get_x() + p.get_width() / 2., height),
                    ha='center', va='bottom',
                    xytext=(0, 10), textcoords='offset points',
                    fontsize=8)

# Plot accuracy comparison for training and testing separately
plt.figure(figsize=(12, 6))
ax = sns.barplot(data=train_accuracies_df, x='Model', y='Train Accuracy', palette='coolwarm')
annotate_bars(ax)
plt.title('Model Training Accuracy Comparison', fontsize=14, pad=24)
plt.ylim(0, 1.0)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

plt.figure(figsize=(12, 6))
ax = sns.barplot(data=accuracies_df, x='Model', y='Test Accuracy', palette='coolwarm')
annotate_bars(ax)
plt.title('Model Testing Accuracy Comparison', fontsize=14, pad=24)
plt.ylim(0, 1.0)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# Plot classification reports
for model_name, report in classification_reports:
    plt.figure(figsize=(10, 6))
    sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True, cmap='Blues', fmt='.2f')
    plt.title(f'Classification Report - {model_name}', fontsize=14, pad=20)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

# Plot confusion matrices
for model_name, cm in confusion_matrices:
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
    plt.title(f'Confusion Matrix - {model_name}', fontsize=14, pad=20)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()